<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
 <!--<![endif]-->
 <head>
  <meta content="noindex" name="robots"/>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   torch.onnx._type_utils — PyTorch 2.7 documentation
  </title>
  <link href="https://pytorch.org/docs/stable/_modules/torch/onnx/_type_utils.html" rel="canonical"/>
  <link href="../../../_static/css/theme.css" rel="stylesheet" type="text/css"/>
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link href="../../../_static/pygments.css" rel="stylesheet" type="text/css"/>
  <link href="../../../_static/css/theme.css" rel="stylesheet" type="text/css"/>
  <link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
  <link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
  <link href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" rel="stylesheet" type="text/css"/>
  <link href="../../../_static/katex-math.css" rel="stylesheet" type="text/css"/>
  <link href="../../../_static/sphinx-dropdown.css" rel="stylesheet" type="text/css"/>
  <link href="../../../_static/panels-bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="../../../_static/css/jit.css" rel="stylesheet" type="text/css"/>
  <link href="../../../_static/css/custom.css" rel="stylesheet" type="text/css"/>
  <link href="../../../genindex.html" rel="index" title="Index"/>
  <link href="../../../search.html" rel="search" title="Search"/>
  <!-- Google Tag Manager -->
  <script>
   (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');
  </script>
  <!-- End Google Tag Manager -->
  <script src="../../../_static/js/modernizr.min.js">
  </script>
  <!-- Preload the theme fonts -->
  <link as="font" crossorigin="anonymous" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
  <!-- Preload the katex fonts -->
  <link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
  <link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
  <link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" rel="stylesheet"/>
 </head>
 <div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
   <div class="header-container">
    <a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/">
    </a>
    <div class="main-menu">
     <ul>
      <li class="main-menu-item">
       <div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
        <a class="with-down-arrow">
         Learn
        </a>
        <div class="resources-dropdown-menu">
         <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
          <span class="dropdown-title">
           Get Started
          </span>
          <p>
           Run PyTorch locally or get started quickly with one of the supported cloud platforms
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
          <span class="dropdown-title">
           Tutorials
          </span>
          <p>
           Whats new in PyTorch tutorials
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
          <span class="dropdown-title">
           Learn the Basics
          </span>
          <p>
           Familiarize yourself with PyTorch concepts and modules
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
          <span class="dropdown-title">
           PyTorch Recipes
          </span>
          <p>
           Bite-size, ready-to-deploy PyTorch code examples
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
          <span class="dropdown-title">
           Intro to PyTorch - YouTube Series
          </span>
          <p>
           Master PyTorch basics with our engaging YouTube tutorial series
          </p>
         </a>
        </div>
       </div>
      </li>
      <li>
       <div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
        <a class="with-down-arrow">
         Ecosystem
        </a>
        <div class="resources-dropdown-menu">
         <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
          <span class="dropdown-title">
           Tools
          </span>
          <p>
           Learn about the tools and frameworks in the PyTorch Ecosystem
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
          <span class="dropdown-title">
           Community
          </span>
          <p>
           Join the PyTorch developer community to contribute, learn, and get your questions answered
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
          <span class="dropdown-title">
           Forums
          </span>
          <p>
           A place to discuss PyTorch code, issues, install, research
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/resources">
          <span class="dropdown-title">
           Developer Resources
          </span>
          <p>
           Find resources and get questions answered
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
          <span class="dropdown-title">
           Contributor Awards - 2024
          </span>
          <p>
           Award winners announced at this year's PyTorch Conference
          </p>
         </a>
        </div>
       </div>
      </li>
      <li>
       <div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
        <a class="with-down-arrow">
         Edge
        </a>
        <div class="resources-dropdown-menu">
         <a class="nav-dropdown-item" href="https://pytorch.org/edge">
          <span class="dropdown-title">
           About PyTorch Edge
          </span>
          <p>
           Build innovative and privacy-aware AI experiences for edge devices
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
          <span class="dropdown-title">
           ExecuTorch
          </span>
          <p>
           End-to-end solution for enabling on-device inference capabilities across mobile and edge devices
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
          <span class="dropdown-title">
           ExecuTorch Docs
          </span>
         </a>
        </div>
       </div>
      </li>
      <li class="main-menu-item">
       <div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
        <a class="with-down-arrow">
         Docs
        </a>
        <div class="resources-dropdown-menu">
         <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
          <span class="dropdown-title">
           PyTorch
          </span>
          <p>
           Explore the documentation for comprehensive guidance on how to use PyTorch
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
          <span class="dropdown-title">
           PyTorch Domains
          </span>
          <p>
           Read the PyTorch Domains documentation to learn more about domain-specific libraries
          </p>
         </a>
        </div>
       </div>
      </li>
      <li>
       <div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
        <a class="with-down-arrow">
         Blogs &amp; News
        </a>
        <div class="resources-dropdown-menu">
         <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
          <span class="dropdown-title">
           PyTorch Blog
          </span>
          <p>
           Catch up on the latest technical news and happenings
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
          <span class="dropdown-title">
           Community Blog
          </span>
          <p>
           Stories from the PyTorch ecosystem
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/videos">
          <span class="dropdown-title">
           Videos
          </span>
          <p>
           Learn about the latest PyTorch tutorials, new, and more
          </p>
          <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
           <span class="dropdown-title">
            Community Stories
           </span>
           <p>
            Learn how our community solves real, everyday machine learning problems with PyTorch
           </p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/events">
           <span class="dropdown-title">
            Events
           </span>
           <p>
            Find events, webinars, and podcasts
           </p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
           <span class="dropdown-title">
            Newsletter
           </span>
           <p>
            Stay up-to-date with the latest updates
           </p>
          </a>
         </a>
        </div>
       </div>
      </li>
      <li>
       <div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
        <a class="with-down-arrow">
         About
        </a>
        <div class="resources-dropdown-menu">
         <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
          <span class="dropdown-title">
           PyTorch Foundation
          </span>
          <p>
           Learn more about the PyTorch Foundation
          </p>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
          <span class="dropdown-title">
           Governing Board
          </span>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/credits">
          <span class="dropdown-title">
           Cloud Credit Program
          </span>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/tac">
          <span class="dropdown-title">
           Technical Advisory Council
          </span>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/staff">
          <span class="dropdown-title">
           Staff
          </span>
         </a>
         <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
          <span class="dropdown-title">
           Contact Us
          </span>
         </a>
        </div>
       </div>
      </li>
      <li class="main-menu-item">
       <div class="no-dropdown">
        <a data-cta="join" href="https://pytorch.org/join">
         Become a Member
        </a>
       </div>
      </li>
      <li>
       <div class="main-menu-item">
        <a class="github-icon" href="https://github.com/pytorch/pytorch">
        </a>
       </div>
      </li>
      <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
     </ul>
    </div>
    <a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#">
    </a>
   </div>
  </div>
 </div>
 <body class="pytorch-body">
  <div class="table-of-contents-link-wrapper">
   <span>
    Table of Contents
   </span>
   <a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#">
   </a>
  </div>
  <nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
   <div class="pytorch-side-scroll">
    <div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
     <div class="pytorch-left-menu-search">
      <div class="version">
       <a href="https://pytorch.org/docs/versions.html">
        2.7 ▼
       </a>
      </div>
      <div id="searchBox">
       <div class="searchbox" id="googleSearchBox">
        <script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e">
        </script>
        <div class="gcse-search">
        </div>
       </div>
       <div id="sphinxSearchBox" style="display: none;">
        <div role="search">
         <form action="../../../search.html" class="wy-form" id="rtd-search-form" method="get">
          <input name="q" placeholder="Search Docs" type="text"/>
          <input name="check_keywords" type="hidden" value="yes"/>
          <input name="area" type="hidden" value="default"/>
         </form>
        </div>
       </div>
      </div>
      <form id="searchForm">
       <label style="margin-bottom: 1rem">
        <input checked="" name="searchType" type="radio" value="google"/>
        Google Search
       </label>
       <label style="margin-bottom: 1rem">
        <input name="searchType" type="radio" value="sphinx"/>
        Classic Search
       </label>
      </form>
      <script>
       document.addEventListener('DOMContentLoaded', function() {
      const searchForm = document.getElementById('searchForm');
      const googleSearchBox = document.getElementById('googleSearchBox');
      const sphinxSearchBox = document.getElementById('sphinxSearchBox');
      // Function to toggle search box visibility
      function toggleSearchBox(searchType) {
        googleSearchBox.style.display = searchType === 'google' ? 'block' : 'none';
        sphinxSearchBox.style.display = searchType === 'sphinx' ? 'block' : 'none';
      }
      // Determine the default search type
      let defaultSearchType;
      const currentUrl = window.location.href;
      if (currentUrl.startsWith('https://pytorch.org/docs/stable')) {
        // For the stable documentation, default to Google
        defaultSearchType = localStorage.getItem('searchType') || 'google';
      } else {
        // For any other version, including docs-preview, default to Sphinx
        defaultSearchType = 'sphinx';
      }
      // Set the default search type
      document.querySelector(`input[name="searchType"][value="${defaultSearchType}"]`).checked = true;
      toggleSearchBox(defaultSearchType);
      // Event listener for changes in search type
      searchForm.addEventListener('change', function(event) {
        const selectedSearchType = event.target.value;
        localStorage.setItem('searchType', selectedSearchType);
        toggleSearchBox(selectedSearchType);
      });
      // Set placeholder text for Google search box
      window.onload = function() {
        var placeholderText = "Search Docs";
        var googleSearchboxText = document.querySelector("#gsc-i-id1");
        if (googleSearchboxText) {
          googleSearchboxText.placeholder = placeholderText;
          googleSearchboxText.style.fontFamily = 'FreightSans';
          googleSearchboxText.style.fontSize = "1.2rem";
          googleSearchboxText.style.color = '#262626';
        }
      };
    });
      </script>
     </div>
     <p class="caption" role="heading">
      <span class="caption-text">
       Community
      </span>
     </p>
     <ul>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../community/build_ci_governance.html">
        PyTorch Governance | Build + CI
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../community/contribution_guide.html">
        PyTorch Contribution Guide
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../community/design.html">
        PyTorch Design Philosophy
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../community/governance.html">
        PyTorch Governance | Mechanics
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../community/persons_of_interest.html">
        PyTorch Governance | Maintainers
       </a>
      </li>
     </ul>
     <p class="caption" role="heading">
      <span class="caption-text">
       Developer Notes
      </span>
     </p>
     <ul>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/amp_examples.html">
        Automatic Mixed Precision examples
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/autograd.html">
        Autograd mechanics
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/broadcasting.html">
        Broadcasting semantics
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/cpu_threading_torchscript_inference.html">
        CPU threading and TorchScript inference
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/cuda.html">
        CUDA semantics
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/custom_operators.html">
        PyTorch Custom Operators Landing Page
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/ddp.html">
        Distributed Data Parallel
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/extending.html">
        Extending PyTorch
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/extending.func.html">
        Extending torch.func with autograd.Function
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/faq.html">
        Frequently Asked Questions
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/fsdp.html">
        FSDP Notes
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/get_start_xpu.html">
        Getting Started on Intel GPU
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/gradcheck.html">
        Gradcheck mechanics
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/hip.html">
        HIP (ROCm) semantics
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/large_scale_deployments.html">
        Features for large-scale deployments
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/libtorch_stable_abi.html">
        LibTorch Stable ABI
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/modules.html">
        Modules
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/mps.html">
        MPS backend
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/multiprocessing.html">
        Multiprocessing best practices
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/numerical_accuracy.html">
        Numerical accuracy
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/randomness.html">
        Reproducibility
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/serialization.html">
        Serialization semantics
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../notes/windows.html">
        Windows FAQ
       </a>
      </li>
     </ul>
     <p class="caption" role="heading">
      <span class="caption-text">
       Language Bindings
      </span>
     </p>
     <ul>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../cpp_index.html">
        C++
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference external" href="https://pytorch.org/javadoc/">
        Javadoc
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../deploy.html">
        torch::deploy
       </a>
      </li>
     </ul>
     <p class="caption" role="heading">
      <span class="caption-text">
       Python API
      </span>
     </p>
     <ul>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../torch.html">
        torch
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../nn.html">
        torch.nn
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../nn.functional.html">
        torch.nn.functional
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../tensors.html">
        torch.Tensor
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../tensor_attributes.html">
        Tensor Attributes
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../tensor_view.html">
        Tensor Views
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../amp.html">
        torch.amp
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../autograd.html">
        torch.autograd
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../library.html">
        torch.library
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../accelerator.html">
        torch.accelerator
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../cpu.html">
        torch.cpu
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../cuda.html">
        torch.cuda
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../torch_cuda_memory.html">
        Understanding CUDA Memory Usage
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../torch_cuda_memory.html#generating-a-snapshot">
        Generating a Snapshot
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../torch_cuda_memory.html#using-the-visualizer">
        Using the visualizer
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../torch_cuda_memory.html#snapshot-api-reference">
        Snapshot API Reference
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../mps.html">
        torch.mps
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../xpu.html">
        torch.xpu
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../mtia.html">
        torch.mtia
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../mtia.memory.html">
        torch.mtia.memory
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../meta.html">
        Meta device
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../backends.html">
        torch.backends
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../export.html">
        torch.export
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributed.html">
        torch.distributed
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributed.tensor.html">
        torch.distributed.tensor
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributed.algorithms.join.html">
        torch.distributed.algorithms.join
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributed.elastic.html">
        torch.distributed.elastic
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../fsdp.html">
        torch.distributed.fsdp
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributed.fsdp.fully_shard.html">
        torch.distributed.fsdp.fully_shard
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributed.tensor.parallel.html">
        torch.distributed.tensor.parallel
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributed.optim.html">
        torch.distributed.optim
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributed.pipelining.html">
        torch.distributed.pipelining
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributed.checkpoint.html">
        torch.distributed.checkpoint
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../distributions.html">
        torch.distributions
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../torch.compiler.html">
        torch.compiler
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../fft.html">
        torch.fft
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../func.html">
        torch.func
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../futures.html">
        torch.futures
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../fx.html">
        torch.fx
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../fx.experimental.html">
        torch.fx.experimental
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../hub.html">
        torch.hub
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../jit.html">
        torch.jit
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../linalg.html">
        torch.linalg
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../monitor.html">
        torch.monitor
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../signal.html">
        torch.signal
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../special.html">
        torch.special
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../torch.overrides.html">
        torch.overrides
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../package.html">
        torch.package
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../profiler.html">
        torch.profiler
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../nn.init.html">
        torch.nn.init
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../nn.attention.html">
        torch.nn.attention
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../onnx.html">
        torch.onnx
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../optim.html">
        torch.optim
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../complex_numbers.html">
        Complex Numbers
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../ddp_comm_hooks.html">
        DDP Communication Hooks
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../quantization.html">
        Quantization
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../rpc.html">
        Distributed RPC Framework
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../random.html">
        torch.random
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../masked.html">
        torch.masked
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../nested.html">
        torch.nested
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../size.html">
        torch.Size
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../sparse.html">
        torch.sparse
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../storage.html">
        torch.Storage
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../testing.html">
        torch.testing
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../utils.html">
        torch.utils
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../benchmark_utils.html">
        torch.utils.benchmark
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../bottleneck.html">
        torch.utils.bottleneck
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../checkpoint.html">
        torch.utils.checkpoint
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../cpp_extension.html">
        torch.utils.cpp_extension
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../data.html">
        torch.utils.data
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../deterministic.html">
        torch.utils.deterministic
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../jit_utils.html">
        torch.utils.jit
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../dlpack.html">
        torch.utils.dlpack
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../mobile_optimizer.html">
        torch.utils.mobile_optimizer
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../model_zoo.html">
        torch.utils.model_zoo
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../tensorboard.html">
        torch.utils.tensorboard
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../module_tracker.html">
        torch.utils.module_tracker
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../type_info.html">
        Type Info
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../named_tensor.html">
        Named Tensors
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../name_inference.html">
        Named Tensors operator coverage
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../config_mod.html">
        torch.__config__
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../future_mod.html">
        torch.__future__
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../logging.html">
        torch._logging
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference internal" href="../../../torch_environment_variables.html">
        Torch Environment Variables
       </a>
      </li>
     </ul>
     <p class="caption" role="heading">
      <span class="caption-text">
       Libraries
      </span>
     </p>
     <ul>
      <li class="toctree-l1">
       <a class="reference external" href="https://pytorch.org/audio/stable">
        torchaudio
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference external" href="https://pytorch.org/data">
        TorchData
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference external" href="https://pytorch.org/torchrec">
        TorchRec
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference external" href="https://pytorch.org/serve">
        TorchServe
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference external" href="https://pytorch.org/text/stable">
        torchtext
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference external" href="https://pytorch.org/vision/stable">
        torchvision
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference external" href="https://pytorch.org/xla/">
        PyTorch on XLA Devices
       </a>
      </li>
      <li class="toctree-l1">
       <a class="reference external" href="https://pytorch.org/ao">
        torchao
       </a>
      </li>
     </ul>
    </div>
   </div>
  </nav>
  <div class="pytorch-container">
   <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
    <div class="pytorch-breadcrumbs-wrapper">
     <div aria-label="breadcrumbs navigation" role="navigation">
      <ul class="pytorch-breadcrumbs">
       <li>
        <a href="../../../index.html">
         Docs
        </a>
        &gt;
       </li>
       <li>
        <a href="../../index.html">
         Module code
        </a>
        &gt;
       </li>
       <li>
        <a href="../../torch.html">
         torch
        </a>
        &gt;
       </li>
       <li>
        <a href="../onnx.html">
         torch.onnx
        </a>
        &gt;
       </li>
       <li>
        torch.onnx._type_utils
       </li>
       <li class="pytorch-breadcrumbs-aside">
       </li>
      </ul>
     </div>
    </div>
    <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
     Shortcuts
    </div>
   </div>
   <section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
    <div class="pytorch-content-left">
     <!-- Google Tag Manager (noscript) -->
     <noscript>
      <iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0">
      </iframe>
     </noscript>
     <!-- End Google Tag Manager (noscript) -->
     <div class="rst-content">
      <div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
       <article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
        <h1>
         Source code for torch.onnx._type_utils
        </h1>
        <div class="highlight">
         <pre>
<span></span><span class="c1"># mypy: allow-untyped-defs</span>
<span class="sd">"""Utilities for converting and operating on ONNX, JIT and torch types."""</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">enum</span>
<span class="kn">import</span> <span class="nn">typing</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Literal</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch._C</span> <span class="kn">import</span> <span class="n">_onnx</span> <span class="k">as</span> <span class="n">_C_onnx</span>
<span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">errors</span>


<span class="k">if</span> <span class="n">typing</span><span class="o">.</span><span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="c1"># Hack to help mypy to recognize torch._C.Value</span>
    <span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">_C</span>  <span class="c1"># noqa: F401</span>

<span class="n">ScalarName</span> <span class="o">=</span> <span class="n">Literal</span><span class="p">[</span>
    <span class="s2">"Byte"</span><span class="p">,</span>
    <span class="s2">"Char"</span><span class="p">,</span>
    <span class="s2">"Double"</span><span class="p">,</span>
    <span class="s2">"Float"</span><span class="p">,</span>
    <span class="s2">"Half"</span><span class="p">,</span>
    <span class="s2">"Int"</span><span class="p">,</span>
    <span class="s2">"Long"</span><span class="p">,</span>
    <span class="s2">"Short"</span><span class="p">,</span>
    <span class="s2">"Bool"</span><span class="p">,</span>
    <span class="s2">"ComplexHalf"</span><span class="p">,</span>
    <span class="s2">"ComplexFloat"</span><span class="p">,</span>
    <span class="s2">"ComplexDouble"</span><span class="p">,</span>
    <span class="s2">"QInt8"</span><span class="p">,</span>
    <span class="s2">"QUInt8"</span><span class="p">,</span>
    <span class="s2">"QInt32"</span><span class="p">,</span>
    <span class="s2">"BFloat16"</span><span class="p">,</span>
    <span class="s2">"Float8E5M2"</span><span class="p">,</span>
    <span class="s2">"Float8E4M3FN"</span><span class="p">,</span>
    <span class="s2">"Float8E5M2FNUZ"</span><span class="p">,</span>
    <span class="s2">"Float8E4M3FNUZ"</span><span class="p">,</span>
    <span class="s2">"Undefined"</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">TorchName</span> <span class="o">=</span> <span class="n">Literal</span><span class="p">[</span>
    <span class="s2">"bool"</span><span class="p">,</span>
    <span class="s2">"uint8_t"</span><span class="p">,</span>
    <span class="s2">"int8_t"</span><span class="p">,</span>
    <span class="s2">"double"</span><span class="p">,</span>
    <span class="s2">"float"</span><span class="p">,</span>
    <span class="s2">"half"</span><span class="p">,</span>
    <span class="s2">"int"</span><span class="p">,</span>
    <span class="s2">"int64_t"</span><span class="p">,</span>
    <span class="s2">"int16_t"</span><span class="p">,</span>
    <span class="s2">"complex32"</span><span class="p">,</span>
    <span class="s2">"complex64"</span><span class="p">,</span>
    <span class="s2">"complex128"</span><span class="p">,</span>
    <span class="s2">"qint8"</span><span class="p">,</span>
    <span class="s2">"quint8"</span><span class="p">,</span>
    <span class="s2">"qint32"</span><span class="p">,</span>
    <span class="s2">"bfloat16"</span><span class="p">,</span>
    <span class="s2">"float8_e5m2"</span><span class="p">,</span>
    <span class="s2">"float8_e4m3fn"</span><span class="p">,</span>
    <span class="s2">"float8_e5m2fnuz"</span><span class="p">,</span>
    <span class="s2">"float8_e4m3fnuz"</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">class</span> <span class="nc">JitScalarType</span><span class="p">(</span><span class="n">enum</span><span class="o">.</span><span class="n">IntEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Scalar types defined in torch.</span>

<span class="sd">    Use ``JitScalarType`` to convert from torch and JIT scalar types to ONNX scalar types.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # xdoctest: +REQUIRES(env:TORCH_DOCTEST_ONNX)</span>
<span class="sd">        &gt;&gt;&gt; # xdoctest: +IGNORE_WANT("win32 has different output")</span>
<span class="sd">        &gt;&gt;&gt; JitScalarType.from_value(torch.ones(1, 2)).onnx_type()</span>
<span class="sd">        TensorProtoDataType.FLOAT</span>

<span class="sd">        &gt;&gt;&gt; JitScalarType.from_value(torch_c_value_with_type_float).onnx_type()</span>
<span class="sd">        TensorProtoDataType.FLOAT</span>

<span class="sd">        &gt;&gt;&gt; JitScalarType.from_dtype(torch.get_default_dtype).onnx_type()</span>
<span class="sd">        TensorProtoDataType.FLOAT</span>

<span class="sd">    """</span>

    <span class="c1"># Order defined in https://github.com/pytorch/pytorch/blob/344defc9733a45fee8d0c4d3f5530f631e823196/c10/core/ScalarType.h</span>
    <span class="n">UINT8</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">INT8</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 1</span>
    <span class="n">INT16</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 2</span>
    <span class="n">INT</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 3</span>
    <span class="n">INT64</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 4</span>
    <span class="n">HALF</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 5</span>
    <span class="n">FLOAT</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 6</span>
    <span class="n">DOUBLE</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 7</span>
    <span class="n">COMPLEX32</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 8</span>
    <span class="n">COMPLEX64</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 9</span>
    <span class="n">COMPLEX128</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 10</span>
    <span class="n">BOOL</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 11</span>
    <span class="n">QINT8</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 12</span>
    <span class="n">QUINT8</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 13</span>
    <span class="n">QINT32</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 14</span>
    <span class="n">BFLOAT16</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 15</span>
    <span class="n">FLOAT8E5M2</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 16</span>
    <span class="n">FLOAT8E4M3FN</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 17</span>
    <span class="n">FLOAT8E5M2FNUZ</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 18</span>
    <span class="n">FLOAT8E4M3FNUZ</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 19</span>
    <span class="n">UNDEFINED</span> <span class="o">=</span> <span class="n">enum</span><span class="o">.</span><span class="n">auto</span><span class="p">()</span>  <span class="c1"># 20</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_from_name</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">ScalarName</span> <span class="o">|</span> <span class="n">TorchName</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">JitScalarType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Convert a JIT scalar type or torch type name to ScalarType.</span>

<span class="sd">        Note: DO NOT USE this API when `name` comes from a `torch._C.Value.type()` calls.</span>
<span class="sd">            A "RuntimeError: INTERNAL ASSERT FAILED at "../aten/src/ATen/core/jit_type_base.h" can</span>
<span class="sd">            be raised in several scenarios where shape info is not present.</span>
<span class="sd">            Instead use `from_value` API which is safer.</span>

<span class="sd">        Args:</span>
<span class="sd">            name: JIT scalar type name (Byte) or torch type name (uint8_t).</span>

<span class="sd">        Returns:</span>
<span class="sd">            JitScalarType</span>

<span class="sd">        Raises:</span>
<span class="sd">           OnnxExporterError: if name is not a valid scalar type name or if it is None.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">OnnxExporterError</span><span class="p">(</span><span class="s2">"Scalar type name cannot be None"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">valid_scalar_name</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">_SCALAR_NAME_TO_TYPE</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>  <span class="c1"># type: ignore[index]</span>
        <span class="k">if</span> <span class="n">valid_torch_name</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">_TORCH_NAME_TO_SCALAR_TYPE</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>  <span class="c1"># type: ignore[index]</span>

        <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">OnnxExporterError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unknown torch or scalar type: '</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">'"</span><span class="p">)</span>

<div class="viewcode-block" id="JitScalarType.from_dtype"><a class="viewcode-back" href="../../../generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.from_dtype">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_dtype</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">JitScalarType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Convert a torch dtype to JitScalarType.</span>

<span class="sd">        Note: DO NOT USE this API when `dtype` comes from a `torch._C.Value.type()` calls.</span>
<span class="sd">            A "RuntimeError: INTERNAL ASSERT FAILED at "../aten/src/ATen/core/jit_type_base.h" can</span>
<span class="sd">            be raised in several scenarios where shape info is not present.</span>
<span class="sd">            Instead use `from_value` API which is safer.</span>

<span class="sd">        Args:</span>
<span class="sd">            dtype: A torch.dtype to create a JitScalarType from</span>

<span class="sd">        Returns:</span>
<span class="sd">            JitScalarType</span>

<span class="sd">        Raises:</span>
<span class="sd">            OnnxExporterError: if dtype is not a valid torch.dtype or if it is None.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_DTYPE_TO_SCALAR_TYPE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">OnnxExporterError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unknown dtype: </span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_DTYPE_TO_SCALAR_TYPE</span><span class="p">[</span><span class="n">dtype</span><span class="p">]</span></div>

<div class="viewcode-block" id="JitScalarType.from_onnx_type"><a class="viewcode-back" href="../../../generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.from_onnx_type">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_onnx_type</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">onnx_type</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">JitScalarType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Convert a ONNX data type to JitScalarType.</span>

<span class="sd">        Args:</span>
<span class="sd">            onnx_type: A torch._C._onnx.TensorProtoDataType to create a JitScalarType from</span>

<span class="sd">        Returns:</span>
<span class="sd">            JitScalarType</span>

<span class="sd">        Raises:</span>
<span class="sd">            OnnxExporterError: if dtype is not a valid torch.dtype or if it is None.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">onnx_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_ONNX_TO_SCALAR_TYPE</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">OnnxExporterError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unknown onnx_type: </span><span class="si">{</span><span class="n">onnx_type</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_ONNX_TO_SCALAR_TYPE</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="p">,</span> <span class="n">onnx_type</span><span class="p">)]</span></div>

<div class="viewcode-block" id="JitScalarType.from_value"><a class="viewcode-back" href="../../../generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.from_value">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_value</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Value</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">JitScalarType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Create a JitScalarType from an value's scalar type.</span>

<span class="sd">        Args:</span>
<span class="sd">            value: An object to fetch scalar type from.</span>
<span class="sd">            default: The JitScalarType to return if a valid scalar cannot be fetched from value</span>

<span class="sd">        Returns:</span>
<span class="sd">            JitScalarType.</span>

<span class="sd">        Raises:</span>
<span class="sd">            OnnxExporterError: if value does not have a valid scalar type and default is None.</span>
<span class="sd">            SymbolicValueError: when value.type()'s info are empty and default is None</span>
<span class="sd">        """</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Value</span><span class="p">)</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">node</span><span class="p">()</span><span class="o">.</span><span class="n">mustBeNone</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="c1"># default value of type JitScalarType is returned when value is not valid</span>
            <span class="k">if</span> <span class="n">default</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">OnnxExporterError</span><span class="p">(</span>
                    <span class="s2">"value must be either torch._C.Value or torch.Tensor objects."</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">default</span><span class="p">,</span> <span class="n">JitScalarType</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">OnnxExporterError</span><span class="p">(</span>
                    <span class="s2">"default value must be a JitScalarType object."</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">default</span>

        <span class="c1"># Each value type has their own way of storing scalar type</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_dtype</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ListType</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_dtype</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">()</span><span class="o">.</span><span class="n">getElementType</span><span class="p">()</span><span class="o">.</span><span class="n">dtype</span><span class="p">())</span>
            <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_from_name</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">()</span><span class="o">.</span><span class="n">getElementType</span><span class="p">()))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">OptionalType</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">()</span><span class="o">.</span><span class="n">getElementType</span><span class="p">()</span><span class="o">.</span><span class="n">dtype</span><span class="p">()</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">default</span><span class="p">,</span> <span class="n">JitScalarType</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">default</span>
                <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">OnnxExporterError</span><span class="p">(</span>
                    <span class="s2">"default value must be a JitScalarType object."</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_dtype</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">()</span><span class="o">.</span><span class="n">getElementType</span><span class="p">()</span><span class="o">.</span><span class="n">dtype</span><span class="p">())</span>

        <span class="n">scalar_type</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">node</span><span class="p">()</span><span class="o">.</span><span class="n">kind</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">"prim::Constant"</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">NoneType</span>
        <span class="p">):</span>
            <span class="c1"># value must be a non-list torch._C.Value scalar</span>
            <span class="n">scalar_type</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">()</span><span class="o">.</span><span class="n">scalarType</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">scalar_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_from_name</span><span class="p">(</span><span class="n">scalar_type</span><span class="p">)</span>

        <span class="c1"># When everything fails... try to default</span>
        <span class="k">if</span> <span class="n">default</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">default</span>
        <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">SymbolicValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Cannot determine scalar type for this '</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">())</span><span class="si">}</span><span class="s2">' instance and "</span>
            <span class="s2">"a default value was not provided."</span><span class="p">,</span>
            <span class="n">value</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="JitScalarType.scalar_name"><a class="viewcode-back" href="../../../generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.scalar_name">[docs]</a>    <span class="k">def</span> <span class="nf">scalar_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScalarName</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Convert a JitScalarType to a JIT scalar type name."""</span>
        <span class="k">return</span> <span class="n">_SCALAR_TYPE_TO_NAME</span><span class="p">[</span><span class="bp">self</span><span class="p">]</span></div>

<div class="viewcode-block" id="JitScalarType.torch_name"><a class="viewcode-back" href="../../../generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.torch_name">[docs]</a>    <span class="k">def</span> <span class="nf">torch_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TorchName</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Convert a JitScalarType to a torch type name."""</span>
        <span class="k">return</span> <span class="n">_SCALAR_TYPE_TO_TORCH_NAME</span><span class="p">[</span><span class="bp">self</span><span class="p">]</span></div>

<div class="viewcode-block" id="JitScalarType.dtype"><a class="viewcode-back" href="../../../generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.dtype">[docs]</a>    <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Convert a JitScalarType to a torch dtype."""</span>
        <span class="k">return</span> <span class="n">_SCALAR_TYPE_TO_DTYPE</span><span class="p">[</span><span class="bp">self</span><span class="p">]</span></div>

<div class="viewcode-block" id="JitScalarType.onnx_type"><a class="viewcode-back" href="../../../generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.onnx_type">[docs]</a>    <span class="k">def</span> <span class="nf">onnx_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Convert a JitScalarType to an ONNX data type."""</span>
        <span class="k">if</span> <span class="bp">self</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_SCALAR_TYPE_TO_ONNX</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">errors</span><span class="o">.</span><span class="n">OnnxExporterError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Scalar type </span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2"> cannot be converted to ONNX"</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">_SCALAR_TYPE_TO_ONNX</span><span class="p">[</span><span class="bp">self</span><span class="p">]</span></div>

<div class="viewcode-block" id="JitScalarType.onnx_compatible"><a class="viewcode-back" href="../../../generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.onnx_compatible">[docs]</a>    <span class="k">def</span> <span class="nf">onnx_compatible</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Return whether this JitScalarType is compatible with ONNX."""</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">self</span> <span class="ow">in</span> <span class="n">_SCALAR_TYPE_TO_ONNX</span>
            <span class="ow">and</span> <span class="bp">self</span> <span class="o">!=</span> <span class="n">JitScalarType</span><span class="o">.</span><span class="n">UNDEFINED</span>
            <span class="ow">and</span> <span class="bp">self</span> <span class="o">!=</span> <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX32</span>
        <span class="p">)</span></div>


<span class="k">def</span> <span class="nf">valid_scalar_name</span><span class="p">(</span><span class="n">scalar_name</span><span class="p">:</span> <span class="n">ScalarName</span> <span class="o">|</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Return whether the given scalar name is a valid JIT scalar type name."""</span>
    <span class="k">return</span> <span class="n">scalar_name</span> <span class="ow">in</span> <span class="n">_SCALAR_NAME_TO_TYPE</span>


<span class="k">def</span> <span class="nf">valid_torch_name</span><span class="p">(</span><span class="n">torch_name</span><span class="p">:</span> <span class="n">TorchName</span> <span class="o">|</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Return whether the given torch name is a valid torch type name."""</span>
    <span class="k">return</span> <span class="n">torch_name</span> <span class="ow">in</span> <span class="n">_TORCH_NAME_TO_SCALAR_TYPE</span>


<span class="c1"># https://github.com/pytorch/pytorch/blob/344defc9733a45fee8d0c4d3f5530f631e823196/c10/core/ScalarType.h</span>
<span class="n">_SCALAR_TYPE_TO_NAME</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">JitScalarType</span><span class="p">,</span> <span class="n">ScalarName</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">BOOL</span><span class="p">:</span> <span class="s2">"Bool"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">UINT8</span><span class="p">:</span> <span class="s2">"Byte"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span> <span class="s2">"Char"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT16</span><span class="p">:</span> <span class="s2">"Short"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT</span><span class="p">:</span> <span class="s2">"Int"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT64</span><span class="p">:</span> <span class="s2">"Long"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">HALF</span><span class="p">:</span> <span class="s2">"Half"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">:</span> <span class="s2">"Float"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">:</span> <span class="s2">"Double"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX32</span><span class="p">:</span> <span class="s2">"ComplexHalf"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX64</span><span class="p">:</span> <span class="s2">"ComplexFloat"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX128</span><span class="p">:</span> <span class="s2">"ComplexDouble"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QINT8</span><span class="p">:</span> <span class="s2">"QInt8"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QUINT8</span><span class="p">:</span> <span class="s2">"QUInt8"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QINT32</span><span class="p">:</span> <span class="s2">"QInt32"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">BFLOAT16</span><span class="p">:</span> <span class="s2">"BFloat16"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E5M2</span><span class="p">:</span> <span class="s2">"Float8E5M2"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E4M3FN</span><span class="p">:</span> <span class="s2">"Float8E4M3FN"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E5M2FNUZ</span><span class="p">:</span> <span class="s2">"Float8E5M2FNUZ"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E4M3FNUZ</span><span class="p">:</span> <span class="s2">"Float8E4M3FNUZ"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">UNDEFINED</span><span class="p">:</span> <span class="s2">"Undefined"</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">_SCALAR_NAME_TO_TYPE</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">ScalarName</span><span class="p">,</span> <span class="n">JitScalarType</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">_SCALAR_TYPE_TO_NAME</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">}</span>

<span class="n">_SCALAR_TYPE_TO_TORCH_NAME</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">JitScalarType</span><span class="p">,</span> <span class="n">TorchName</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">BOOL</span><span class="p">:</span> <span class="s2">"bool"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">UINT8</span><span class="p">:</span> <span class="s2">"uint8_t"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span> <span class="s2">"int8_t"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT16</span><span class="p">:</span> <span class="s2">"int16_t"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT</span><span class="p">:</span> <span class="s2">"int"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT64</span><span class="p">:</span> <span class="s2">"int64_t"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">HALF</span><span class="p">:</span> <span class="s2">"half"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">:</span> <span class="s2">"float"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">:</span> <span class="s2">"double"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX32</span><span class="p">:</span> <span class="s2">"complex32"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX64</span><span class="p">:</span> <span class="s2">"complex64"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX128</span><span class="p">:</span> <span class="s2">"complex128"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QINT8</span><span class="p">:</span> <span class="s2">"qint8"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QUINT8</span><span class="p">:</span> <span class="s2">"quint8"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QINT32</span><span class="p">:</span> <span class="s2">"qint32"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">BFLOAT16</span><span class="p">:</span> <span class="s2">"bfloat16"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E5M2</span><span class="p">:</span> <span class="s2">"float8_e5m2"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E4M3FN</span><span class="p">:</span> <span class="s2">"float8_e4m3fn"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E5M2FNUZ</span><span class="p">:</span> <span class="s2">"float8_e5m2fnuz"</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E4M3FNUZ</span><span class="p">:</span> <span class="s2">"float8_e4m3fnuz"</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">_TORCH_NAME_TO_SCALAR_TYPE</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">TorchName</span><span class="p">,</span> <span class="n">JitScalarType</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">_SCALAR_TYPE_TO_TORCH_NAME</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">}</span>

<span class="n">_SCALAR_TYPE_TO_ONNX</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">BOOL</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">BOOL</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">UINT8</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">UINT8</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">INT8</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT16</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">INT16</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">INT32</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT64</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">HALF</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">FLOAT16</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX64</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">COMPLEX64</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX128</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">COMPLEX128</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">BFLOAT16</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">BFLOAT16</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">UNDEFINED</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">UNDEFINED</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX32</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">UNDEFINED</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QINT8</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">INT8</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QUINT8</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">UINT8</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QINT32</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">INT32</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E5M2</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">FLOAT8E5M2</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E4M3FN</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">FLOAT8E4M3FN</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E5M2FNUZ</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">FLOAT8E5M2FNUZ</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E4M3FNUZ</span><span class="p">:</span> <span class="n">_C_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span><span class="o">.</span><span class="n">FLOAT8E4M3FNUZ</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">_ONNX_TO_SCALAR_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">_SCALAR_TYPE_TO_ONNX</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="c1"># source of truth is</span>
<span class="c1"># https://github.com/pytorch/pytorch/blob/master/torch/csrc/utils/tensor_dtypes.cpp</span>
<span class="n">_SCALAR_TYPE_TO_DTYPE</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">BOOL</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">UINT8</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT16</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">short</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">INT64</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">HALF</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX32</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex32</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX64</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex64</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">COMPLEX128</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex128</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QINT8</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">qint8</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QUINT8</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">quint8</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">QINT32</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">qint32</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">BFLOAT16</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E5M2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float8_e5m2</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E4M3FN</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float8_e4m3fn</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E5M2FNUZ</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float8_e5m2fnuz</span><span class="p">,</span>
    <span class="n">JitScalarType</span><span class="o">.</span><span class="n">FLOAT8E4M3FNUZ</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float8_e4m3fnuz</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">_DTYPE_TO_SCALAR_TYPE</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">_SCALAR_TYPE_TO_DTYPE</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</pre>
        </div>
       </article>
      </div>
      <footer>
       <hr/>
       <div role="contentinfo">
        <p>
         © Copyright PyTorch Contributors.
        </p>
       </div>
       <div>
        Built with
        <a href="http://sphinx-doc.org/">
         Sphinx
        </a>
        using a
        <a href="https://github.com/rtfd/sphinx_rtd_theme">
         theme
        </a>
        provided by
        <a href="https://readthedocs.org">
         Read the Docs
        </a>
        .
       </div>
      </footer>
     </div>
     <script>
      var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
     </script>
    </div>
    <div class="pytorch-content-right" id="pytorch-content-right">
     <div class="pytorch-right-menu" id="pytorch-right-menu">
      <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
      </div>
     </div>
    </div>
   </section>
  </div>
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js" type="text/javascript">
  </script>
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js">
  </script>
  <script src="../../../_static/jquery.js">
  </script>
  <script src="../../../_static/underscore.js">
  </script>
  <script src="../../../_static/_sphinx_javascript_frameworks_compat.js">
  </script>
  <script src="../../../_static/doctools.js">
  </script>
  <script src="../../../_static/sphinx_highlight.js">
  </script>
  <script src="../../../_static/clipboard.min.js">
  </script>
  <script src="../../../_static/copybutton.js">
  </script>
  <script src="../../../_static/js/vendor/popper.min.js" type="text/javascript">
  </script>
  <script src="../../../_static/js/vendor/bootstrap.min.js" type="text/javascript">
  </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js">
  </script>
  <script src="../../../_static/js/theme.js" type="text/javascript">
  </script>
  <script type="text/javascript">
   jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
  <script script="" type="text/javascript">
   var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
  </script>
  <img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
  <!-- Begin Footer -->
  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
   <div class="container">
    <div class="row">
     <div class="col-md-4 text-center">
      <h2>
       Docs
      </h2>
      <p>
       Access comprehensive developer documentation for PyTorch
      </p>
      <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">
       View Docs
      </a>
     </div>
     <div class="col-md-4 text-center">
      <h2>
       Tutorials
      </h2>
      <p>
       Get in-depth tutorials for beginners and advanced developers
      </p>
      <a class="with-right-arrow" href="https://pytorch.org/tutorials">
       View Tutorials
      </a>
     </div>
     <div class="col-md-4 text-center">
      <h2>
       Resources
      </h2>
      <p>
       Find development resources and get your questions answered
      </p>
      <a class="with-right-arrow" href="https://pytorch.org/resources">
       View Resources
      </a>
     </div>
    </div>
   </div>
  </div>
  <footer class="site-footer">
   <div class="container footer-container">
    <div class="footer-logo-wrapper">
     <a class="footer-logo" href="https://pytorch.org/">
     </a>
    </div>
    <div class="footer-links-wrapper">
     <div class="footer-links-col">
      <ul>
       <li class="list-title">
        <a href="https://pytorch.org/">
         PyTorch
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/get-started">
         Get Started
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/features">
         Features
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/ecosystem">
         Ecosystem
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/blog/">
         Blog
        </a>
       </li>
       <li>
        <a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">
         Contributing
        </a>
       </li>
      </ul>
     </div>
     <div class="footer-links-col">
      <ul>
       <li class="list-title">
        <a href="https://pytorch.org/resources">
         Resources
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/tutorials">
         Tutorials
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/docs/stable/index.html">
         Docs
        </a>
       </li>
       <li>
        <a href="https://discuss.pytorch.org" target="_blank">
         Discuss
        </a>
       </li>
       <li>
        <a href="https://github.com/pytorch/pytorch/issues" target="_blank">
         Github Issues
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">
         Brand Guidelines
        </a>
       </li>
      </ul>
     </div>
     <div class="footer-links-col">
      <ul>
       <li class="list-title">
        Stay up to date
       </li>
       <li>
        <a href="https://www.facebook.com/pytorch" target="_blank">
         Facebook
        </a>
       </li>
       <li>
        <a href="https://twitter.com/pytorch" target="_blank">
         Twitter
        </a>
       </li>
       <li>
        <a href="https://www.youtube.com/pytorch" target="_blank">
         YouTube
        </a>
       </li>
       <li>
        <a href="https://www.linkedin.com/company/pytorch" target="_blank">
         LinkedIn
        </a>
       </li>
      </ul>
     </div>
     <div class="footer-links-col">
      <ul>
       <li class="list-title">
        PyTorch Podcasts
       </li>
       <li>
        <a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">
         Spotify
        </a>
       </li>
       <li>
        <a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">
         Apple
        </a>
       </li>
       <li>
        <a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">
         Google
        </a>
       </li>
       <li>
        <a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">
         Amazon
        </a>
       </li>
      </ul>
     </div>
    </div>
    <div class="privacy-policy">
     <ul>
      <li class="privacy-policy-links">
       <a href="https://www.linuxfoundation.org/terms/" target="_blank">
        Terms
       </a>
      </li>
      <li class="privacy-policy-links">
       |
      </li>
      <li class="privacy-policy-links">
       <a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">
        Privacy
       </a>
      </li>
     </ul>
    </div>
    <div class="copyright">
     <p>
      © Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
      <a href="https://www.linuxfoundation.org/policies/">
       www.linuxfoundation.org/policies/
      </a>
      . The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see
      <a href="https://www.lfprojects.org/policies/">
       www.lfprojects.org/policies/
      </a>
      .
     </p>
    </div>
   </div>
  </footer>
  <div class="cookie-banner-wrapper">
   <div class="container">
    <p class="gdpr-notice">
     To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls:
     <a href="https://www.facebook.com/policies/cookies/">
      Cookies Policy
     </a>
     .
    </p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg"/>
   </div>
  </div>
  <!-- End Footer -->
  <!-- Begin Mobile Menu -->
  <div class="mobile-main-menu">
   <div class="container-fluid">
    <div class="container">
     <div class="mobile-main-menu-header-container">
      <a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/">
      </a>
      <a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#">
      </a>
     </div>
    </div>
   </div>
   <div class="mobile-main-menu-links-container">
    <div class="main-menu">
     <ul>
      <li class="resources-mobile-menu-title">
       <a>
        Learn
       </a>
      </li>
      <ul class="resources-mobile-menu-items">
       <li>
        <a href="https://pytorch.org/get-started">
         Get Started
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/tutorials">
         Tutorials
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">
         Learn the Basics
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">
         PyTorch Recipes
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/tutorials/beginner/introyt.html">
         Introduction to PyTorch - YouTube Series
        </a>
       </li>
      </ul>
      <li class="resources-mobile-menu-title">
       <a>
        Ecosystem
       </a>
      </li>
      <ul class="resources-mobile-menu-items">
       <li>
        <a href="https://pytorch.org/ecosystem">
         Tools
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/#community-module">
         Community
        </a>
       </li>
       <li>
        <a href="https://discuss.pytorch.org/">
         Forums
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/resources">
         Developer Resources
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/ecosystem/contributor-awards-2023">
         Contributor Awards - 2024
        </a>
       </li>
      </ul>
      <li class="resources-mobile-menu-title">
       <a>
        Edge
       </a>
      </li>
      <ul class="resources-mobile-menu-items">
       <li>
        <a href="https://pytorch.org/edge">
         About PyTorch Edge
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/executorch-overview">
         ExecuTorch
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/executorch/stable/index.html">
         ExecuTorch Documentation
        </a>
       </li>
      </ul>
      <li class="resources-mobile-menu-title">
       <a>
        Docs
       </a>
      </li>
      <ul class="resources-mobile-menu-items">
       <li>
        <a href="https://pytorch.org/docs/stable/index.html">
         PyTorch
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/pytorch-domains">
         PyTorch Domains
        </a>
       </li>
      </ul>
      <li class="resources-mobile-menu-title">
       <a>
        Blog &amp; News
       </a>
      </li>
      <ul class="resources-mobile-menu-items">
       <li>
        <a href="https://pytorch.org/blog/">
         PyTorch Blog
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/community-blog">
         Community Blog
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/videos">
         Videos
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/community-stories">
         Community Stories
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/events">
         Events
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/newsletter">
         Newsletter
        </a>
       </li>
      </ul>
      <li class="resources-mobile-menu-title">
       <a>
        About
       </a>
      </li>
      <ul class="resources-mobile-menu-items">
       <li>
        <a href="https://pytorch.org/foundation">
         PyTorch Foundation
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/governing-board">
         Governing Board
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/credits">
         Cloud Credit Program
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/tac">
         Technical Advisory Council
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/staff">
         Staff
        </a>
       </li>
       <li>
        <a href="https://pytorch.org/contact-us">
         Contact Us
        </a>
       </li>
      </ul>
     </ul>
    </div>
   </div>
  </div>
  <!-- End Mobile Menu -->
  <script src="../../../_static/js/vendor/anchor.min.js" type="text/javascript">
  </script>
  <script type="text/javascript">
   $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
 </body>
</html>
